{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias y path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "from collections import Counter\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "\n",
    "#file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "file_path2 = \"C:\\\\Users\\\\JuanJo\\\\Desktop\\\\LATAM\\\\Challenge\\\\farmers-protest-tweets-2021-2-4.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df\n",
    "\n",
    "Tweet original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.read_json(file_path2, lines=True)\n",
    "df=df0.dropna(axis=1, how='all')\n",
    "df['fecha'] = df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_users\n",
    "\n",
    "detalles de cada user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = json_normalize(df['user'])\n",
    "df_users['fecha'] = df['fecha'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acotado2=df[['id','media']]\n",
    "df_acotado3=df[['id','quotedTweet']]\n",
    "df_acotado4=df[['id','mentionedUsers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dato=df_acotado2.iloc[0].media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_media\n",
    "detalles de informacion tipo media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expandido = df_acotado2.explode('media')\n",
    "df_media = json_normalize(df_expandido['media'])\n",
    "df_media['id_prim'] = df_expandido['id'].values\n",
    "df_media=df_media.dropna(axis=1, how='all')\n",
    "df_media2 = df_media[df_media['type'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_quotedTweet\n",
    "\n",
    "reTweetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuanJo\\AppData\\Local\\Temp\\ipykernel_17556\\1096978238.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_quotedTweet3['fecha'] = pd.to_datetime(df_quotedTweet3['date']).dt.strftime('%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "df_quotedTweet = json_normalize(df['quotedTweet'])\n",
    "df_quotedTweet['id_prim'] = df_acotado3['id'].values\n",
    "df_quotedTweet2 = df_quotedTweet[df_quotedTweet['id'].notnull()]\n",
    "df_quotedTweet3=df_quotedTweet2.dropna(axis=1, how='all')\n",
    "df_quotedTweet3['fecha'] = pd.to_datetime(df_quotedTweet3['date']).dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_mentionedUsers\n",
    "\n",
    "Usuarios mencionados en tweet original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expandido = df_acotado4.explode('mentionedUsers')\n",
    "df_mentionedUsers = json_normalize(df_expandido['mentionedUsers'])\n",
    "df_mentionedUsers['id_prim'] = df_expandido['id'].values\n",
    "df_mentionedUsers=df_mentionedUsers.dropna(axis=1, how='all')\n",
    "df_mentionedUsers2 = df_mentionedUsers[df_mentionedUsers['id'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_mentionedUsers_quot\n",
    "\n",
    "usuarios mencionados en retweeteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_quotedTweet3_acotado=df_quotedTweet3[['id','id_prim','user.username','user.id','mentionedUsers']]\n",
    "df_quotedTweet3_acotado=df_quotedTweet3[['id','mentionedUsers']]\n",
    "df_quotedTweet3_acotado = df_quotedTweet3_acotado[df_quotedTweet3_acotado['mentionedUsers'].notnull()]\n",
    "\n",
    "df_expandido = df_quotedTweet3_acotado.explode('mentionedUsers')\n",
    "df_mentionedUsers_quot = json_normalize(df_expandido['mentionedUsers'])\n",
    "df_mentionedUsers_quot['id_second'] = df_expandido['id'].values\n",
    "df_mentionedUsers_quot=df_mentionedUsers_quot.dropna(axis=1, how='all')\n",
    "\n",
    "#dato=df_quotedTweet3_acotado.iloc[0].mentionedUsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas seguimiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dato0_df=df_quotedTweet3.loc[0]\n",
    "dato0_idprim=df_quotedTweet3.iloc[0].id_prim\n",
    "dato0_id=int(df_quotedTweet3.iloc[0].id)\n",
    "dato0_2_comp=dato0_df.mentionedUsers\n",
    "\n",
    "dato2_df=df[df['id']==dato0_idprim].loc[0]\n",
    "\n",
    "\n",
    "dato2_2_df=df_mentionedUsers2[df_mentionedUsers2['id_prim']==dato0_idprim]\n",
    "dato0_2_df=df_mentionedUsers_quot[df_mentionedUsers_quot['id_second']==dato0_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1\n",
    "\n",
    "##### a- top10 fechas con más tweets\n",
    "###### a- Considerando los retweets un tweet por si mismo se hace la suma de los ids por fechas de los tweet y los retweets y se rankea fechas principales.\n",
    "\n",
    "##### b- usuarios con más publicaciones dichos dias\n",
    "###### b- Con estas fechas se cuentan los usarios que emitieron tweets y retweets y se obtiene el maximo usuario para estas 10 fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrup = df.groupby(df['fecha'])['id'].count()\n",
    "#print(len(df[df['fecha']=='2021-02-23'])) ##comprobacion\n",
    "df_retw_agrup = df_quotedTweet3.groupby(df_quotedTweet3['fecha'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionar los DataFrames en función de las fechas\n",
    "df_merged = pd.merge(df_agrup, df_retw_agrup, on='fecha', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_merged['cantidad_total'] = df_merged['id_dftweets'].fillna(0) + df_merged['id_dfretweets'].fillna(0)\n",
    "\n",
    "df_merged_sorted = df_merged.sort_values(by='cantidad_total', ascending=False)\n",
    "top_10_fechas = df_merged_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso especifico para una fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_agrup_0 = df_users.groupby(df_users[df_users['fecha']==top_10_fechas.index[0]]['username'])['id'].count()#.sum() #calza\n",
    "#print(len(df_users[df_users['fecha']==top_10_fechas.index[0]]))\n",
    "\n",
    "\n",
    "df_retwet_agrup_0 = df_quotedTweet3.groupby(df_quotedTweet3[df_quotedTweet3['fecha']==top_10_fechas.index[0]]['user.username'])['user.id'].count()#.sum() #calza\n",
    "#df_retwet_agrup_0=df_retwet_agrup_0.rename({'user.id':'id'})\n",
    "\n",
    "df_retwet_agrup_0.rename(\"id\",inplace=True)\n",
    "df_retwet_agrup_0.index.name=\"username\"\n",
    "#df_retwet_agrup_0.rename(\"username\",axis='index',inplace=True)\n",
    "#print(len(df_quotedTweet3[df_quotedTweet3['fecha']==top_10_fechas.index[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged_users = pd.merge(df_user_agrup_0, df_retwet_agrup_0, on='username', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_merged_users ['cantidad_total'] = df_merged_users ['id_dftweets'].fillna(0) + df_merged_users ['id_dfretweets'].fillna(0)\n",
    "\n",
    "df_merged_users_sorted = df_merged_users .sort_values(by='cantidad_total', ascending=False)\n",
    "top_1 = df_merged_users_sorted.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciclo for para respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_data = {'Fecha': [], 'Usuario':[]}\n",
    "P1 = pd.DataFrame(data=P1_data)\n",
    "\n",
    "\n",
    "for i in top_10_fechas.index:\n",
    "\n",
    "    df_user_agrup_0 = df_users.groupby(df_users[df_users['fecha']==i]['username'])['id'].count()\n",
    "    df_retwet_agrup_0 = df_quotedTweet3.groupby(df_quotedTweet3[df_quotedTweet3['fecha']==i]['user.username'])['user.id'].count()\n",
    "    df_retwet_agrup_0.rename(\"id\",inplace=True)\n",
    "    df_retwet_agrup_0.index.name=\"username\"\n",
    "    df_merged_users = pd.merge(df_user_agrup_0, df_retwet_agrup_0, on='username', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "    df_merged_users ['cantidad_total'] = df_merged_users ['id_dftweets'].fillna(0) + df_merged_users ['id_dfretweets'].fillna(0)\n",
    "    df_merged_users_sorted = df_merged_users .sort_values(by='cantidad_total', ascending=False)\n",
    "    top_1 = df_merged_users_sorted.head(1)\n",
    "    P1.loc[len(P1)] = np.array([i,top_1.index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1\n",
    "P1['Fecha'] = pd.to_datetime(P1['Fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RaviSinghKA'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 14), 'ndtv'), (datetime.date(2021, 2, 16), 'sikh_coalition'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'RaviSinghKA'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 23), 'Kisanektamorcha'), (datetime.date(2021, 2, 20), 'MangalJ23056160')]\n"
     ]
    }
   ],
   "source": [
    "output_list_P1 = [(fecha.date(), usuario) for fecha, usuario in zip(P1['Fecha'], P1['Usuario'])]\n",
    "print(output_list_P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del P1, P1_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version mas acotada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_users(df_fechas,df_users,df_retweets):\n",
    "    P1_data = {'Fecha': [], 'Usuario':[]}\n",
    "    P1 = pd.DataFrame(data=P1_data)\n",
    "    for i in df_fechas.index:\n",
    "        df_user_agrup = df_users.groupby(df_users[df_users['date']==i]['username'])['id'].count()\n",
    "        df_retwet_agrup = df_retweets.groupby(df_retweets[df_retweets['date']==i]['user.username'])['user.id'].count()\n",
    "        df_retwet_agrup.rename(\"id\",inplace=True)\n",
    "        df_retwet_agrup.index.name=\"username\"\n",
    "        df_merged_users = pd.merge(df_user_agrup, df_retwet_agrup, on='username', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "        df_merged_users ['cantidad_total'] = df_merged_users ['id_dftweets'].fillna(0) + df_merged_users ['id_dfretweets'].fillna(0)\n",
    "        top_1 = df_merged_users.sort_values(by='cantidad_total', ascending=False).head(1)\n",
    "        P1.loc[len(P1)] = np.array([i,top_1.index[0]])    \n",
    "    P1['Fecha'] = pd.to_datetime(P1['Fecha'])\n",
    "    return P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['date','id','user','quotedTweet']\n",
    "data = []\n",
    "file_name = file_path2\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        doc = json.loads(line)\n",
    "        lst = [doc['date'], doc['id'],doc['user'],doc['quotedTweet']]\n",
    "        data.append(lst)\n",
    "\n",
    "df_P1 = pd.DataFrame(data=data, columns=cols)\n",
    "df_P1['date'] = pd.to_datetime(df_P1['date']).dt.strftime('%Y-%m-%d')\n",
    "df_P1['id'] = df_P1['id'].astype('int8') #MEM\n",
    "cols.clear() #MEM\n",
    "data.clear() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P1_quotedTweet = json_normalize(df_P1['quotedTweet'])[['id','date','user.id','user.username']]\n",
    "df_P1_quotedTweet = df_P1_quotedTweet[df_P1_quotedTweet['id'].notnull()]\n",
    "df_P1_quotedTweet['id'] = df_P1_quotedTweet['id'].astype('int8')#MEM\n",
    "df_P1_quotedTweet['date'] = pd.to_datetime(df_P1_quotedTweet['date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P1_users = json_normalize(df_P1['user'])[['id','username']]\n",
    "df_P1_users['date'] = df_P1['date'].values\n",
    "df_P1_users['id'] = df_P1_users['id'].astype('int8')#MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P1_agrup = df_P1.groupby(df_P1['date'])['id'].count()\n",
    "df_P1_retw_agrup = df_P1_quotedTweet.groupby(df_P1_quotedTweet['date'])['id'].count()\n",
    "\n",
    "del df_P1 #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P1_merged = pd.merge(df_P1_agrup, df_P1_retw_agrup, on='date', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_P1_merged['cantidad_total'] = df_P1_merged['id_dftweets'].fillna(0) + df_P1_merged['id_dfretweets'].fillna(0)\n",
    "df_P1_merged = df_P1_merged.sort_values(by='cantidad_total', ascending=False).head(10)\n",
    "\n",
    "del df_P1_agrup, df_P1_retw_agrup #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1_short = rank_users(df_P1_merged,df_P1_users,df_P1_quotedTweet)\n",
    "\n",
    "del df_P1_users,df_P1_quotedTweet,df_P1_merged #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RaviSinghKA'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 14), 'ndtv'), (datetime.date(2021, 2, 16), 'sikh_coalition'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'RaviSinghKA'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 23), 'Kisanektamorcha'), (datetime.date(2021, 2, 20), 'MangalJ23056160')]\n"
     ]
    }
   ],
   "source": [
    "output_list_P1 = [(fecha.date(), usuario) for fecha, usuario in zip(P1_short['Fecha'], P1_short['Usuario'])]\n",
    "del P1_short #MEM\n",
    "gc.collect()\n",
    "print(output_list_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2\n",
    "\n",
    "##### a- top10 emojis más usados\n",
    "###### a- Considerando los retweets un tweet por si mismo se busca en cada content la existencia de emojis y se cuentan.\n",
    "\n",
    "##### b- conteo de estos emojis\n",
    "###### b- Se hace la suma general de todo por emoji y se rankea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = []\n",
    "for i in df['content']:\n",
    "    emojis += [c for c in i if c in emoji.EMOJI_DATA]\n",
    "conteo_emojis = Counter(emojis)\n",
    "df_emojis_twet = pd.DataFrame(list(conteo_emojis.items()), columns=['emoji', 'cantidad'])\n",
    "df_emojis_twet.set_index('emoji', inplace=True)\n",
    "#print(df_emojis_twet)\n",
    "\n",
    "emojis_ret = []\n",
    "for i in df_quotedTweet3['content']:\n",
    "    emojis_ret += [c for c in i if c in emoji.EMOJI_DATA]\n",
    "conteo_emojis = Counter(emojis_ret)\n",
    "df_emojis_retwet = pd.DataFrame(list(conteo_emojis.items()), columns=['emoji', 'cantidad'])\n",
    "df_emojis_retwet.set_index('emoji', inplace=True)\n",
    "#print(df_emojis_retwet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_emoji = pd.merge(df_emojis_twet, df_emojis_retwet, on='emoji', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_merged_emoji ['cantidad_total'] = df_merged_emoji ['cantidad_dftweets'].fillna(0) + df_merged_emoji ['cantidad_dfretweets'].fillna(0)\n",
    "\n",
    "df_merged_emoji_sorted = df_merged_emoji.sort_values(by='cantidad_total', ascending=False)\n",
    "top_10_emoji = df_merged_emoji_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_emoji=top_10_emoji.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuanJo\\AppData\\Local\\Temp\\ipykernel_17556\\3427506781.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  P2['cantidad_total'] = P2['cantidad_total'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "P2=top_10_emoji[['emoji','cantidad_total']]\n",
    "P2['cantidad_total'] = P2['cantidad_total'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 8916), ('😂', 4067), ('🚜', 3274), ('✊', 3046), ('🏻', 2696), ('🌾', 2652), ('❤', 2263), ('🤣', 2110), ('👉', 1895), ('👇', 1691)]\n"
     ]
    }
   ],
   "source": [
    "output_list_P2 = [(emo, int(cantidad)) for emo, cantidad in zip(P2['emoji'], P2['cantidad_total'])]\n",
    "print(output_list_P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version mas acotada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['content','quotedTweet']\n",
    "data = []\n",
    "file_name = file_path2\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        doc = json.loads(line)\n",
    "        lst = [doc['content'], doc['quotedTweet']]\n",
    "        data.append(lst)\n",
    "\n",
    "df_P2 = pd.DataFrame(data=data, columns=cols)\n",
    "cols.clear() #MEM\n",
    "data.clear() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P2_quotedTweet = json_normalize(df_P2['quotedTweet'])[['content']]\n",
    "df_P2_quotedTweet = df_P2_quotedTweet[df_P2_quotedTweet['content'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_P2 = []\n",
    "for i in df_P2['content']:\n",
    "    emojis_P2 += [c for c in i if c in emoji.EMOJI_DATA]\n",
    "conteo_emojis = Counter(emojis_P2)\n",
    "df_P2_emojis_twet = pd.DataFrame(list(conteo_emojis.items()), columns=['emoji', 'cantidad'])\n",
    "df_P2_emojis_twet.set_index('emoji', inplace=True)\n",
    "\n",
    "emojis_P2.clear()#MEM\n",
    "conteo_emojis.clear()#MEM\n",
    "del df_P2#MEM\n",
    "gc.collect() #MEM\n",
    "\n",
    "emojis_P2_ret = []\n",
    "for i in df_P2_quotedTweet['content']:\n",
    "    emojis_P2_ret += [c for c in i if c in emoji.EMOJI_DATA]\n",
    "conteo_emojis = Counter(emojis_P2_ret)\n",
    "df_P2_emojis_retwet = pd.DataFrame(list(conteo_emojis.items()), columns=['emoji', 'cantidad'])\n",
    "df_P2_emojis_retwet.set_index('emoji', inplace=True)\n",
    "\n",
    "emojis_P2_ret.clear()#MEM\n",
    "conteo_emojis.clear()#MEM\n",
    "del df_P2_quotedTweet#MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P2_merged_emoji = pd.merge(df_P2_emojis_twet, df_P2_emojis_retwet, on='emoji', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_P2_merged_emoji ['cantidad_total'] = df_P2_merged_emoji ['cantidad_dftweets'].fillna(0) + df_P2_merged_emoji ['cantidad_dfretweets'].fillna(0)\n",
    "df_P2_merged_emoji = df_P2_merged_emoji.sort_values(by='cantidad_total', ascending=False).head(10).reset_index()\n",
    "\n",
    "del df_P2_emojis_twet,df_P2_emojis_retwet#MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuanJo\\AppData\\Local\\Temp\\ipykernel_17556\\3829611335.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  P2_short['cantidad_total'] = P2_short['cantidad_total'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2_short=df_P2_merged_emoji[['emoji','cantidad_total']]\n",
    "P2_short['cantidad_total'] = P2_short['cantidad_total'].astype(int)\n",
    "\n",
    "del df_P2_merged_emoji #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 8916), ('😂', 4067), ('🚜', 3274), ('✊', 3046), ('🏻', 2696), ('🌾', 2652), ('❤', 2263), ('🤣', 2110), ('👉', 1895), ('👇', 1691)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list_P2 = [(emo, int(cantidad)) for emo, cantidad in zip(P2_short['emoji'], P2_short['cantidad_total'])]\n",
    "print(output_list_P2)\n",
    "\n",
    "del P2_short #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3\n",
    "\n",
    "##### a- top10 historico users con más menciones\n",
    "###### a- Considerando los retweets un tweet por si mismo se busca en en los dataframes de usarios mencionados y usuarios mencionados en los retweets cada aparicion de usuarios.\n",
    "\n",
    "##### b- conteo de estas menciones\n",
    "###### b- Se hace la suma general de todo por usuario y se rankea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrup_hist = df_mentionedUsers2.groupby(df_mentionedUsers2['username'])['id'].count()\n",
    "#print(len(df[df['fecha']=='2021-02-23'])) ##comprobacion\n",
    "df_retw_hist_agrup = df_mentionedUsers_quot.groupby(df_mentionedUsers_quot['username'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_menc = pd.merge(df_agrup_hist, df_retw_hist_agrup, on='username', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_merged_menc['cantidad_total'] = df_merged_menc['id_dftweets'].fillna(0) + df_merged_menc['id_dfretweets'].fillna(0)\n",
    "\n",
    "df_merged_menc_sorted = df_merged_menc.sort_values(by='cantidad_total', ascending=False)\n",
    "top_10_menciones = df_merged_menc_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_menciones=top_10_menciones.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3=top_10_menciones[['username','cantidad_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuanJo\\AppData\\Local\\Temp\\ipykernel_17556\\670438264.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  P3['cantidad_total'] = P3['cantidad_total'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "P3\n",
    "P3['cantidad_total'] = P3['cantidad_total'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2623), ('Kisanektamorcha', 2045), ('RakeshTikaitBKU', 1848), ('PMOIndia', 1560), ('GretaThunberg', 1274), ('RahulGandhi', 1252), ('rihanna', 1142), ('DelhiPolice', 1134), ('RaviSinghKA', 1127), ('UNHumanRights', 1057)]\n"
     ]
    }
   ],
   "source": [
    "output_list_P3 = [(username, int(cantidad)) for username, cantidad in zip(P3['username'], P3['cantidad_total'])]\n",
    "print(output_list_P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version mas acotada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mentionedUsers','quotedTweet']\n",
    "data = []\n",
    "file_name = file_path2\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        doc = json.loads(line)\n",
    "        lst = [doc['mentionedUsers'], doc['quotedTweet']]\n",
    "        data.append(lst)\n",
    "\n",
    "df_P3 = pd.DataFrame(data=data, columns=cols)\n",
    "\n",
    "cols.clear() #MEM\n",
    "data.clear() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P3_mentionedUsers=df_P3.explode('mentionedUsers')\n",
    "df_P3_mentionedUsers = json_normalize(df_P3_mentionedUsers['mentionedUsers'])[['id','username']]\n",
    "df_P3_mentionedUsers = df_P3_mentionedUsers[df_P3_mentionedUsers['id'].notnull()]\n",
    "df_P3_mentionedUsers['id'] = df_P3_mentionedUsers['id'].astype('int8') #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P3_quotedTweet = json_normalize(df_P3['quotedTweet'])[['mentionedUsers']]\n",
    "df_P3_quotedTweet = df_P3_quotedTweet[df_P3_quotedTweet['mentionedUsers'].notnull()]\n",
    "\n",
    "df_P3_mentionedUsers_quot=df_P3_quotedTweet.explode('mentionedUsers')\n",
    "df_P3_mentionedUsers_quot = json_normalize(df_P3_mentionedUsers_quot['mentionedUsers'])[['id','username']]\n",
    "df_P3_mentionedUsers_quot['id'] = df_P3_mentionedUsers_quot['id'].astype('int8') #MEM\n",
    "\n",
    "del df_P3_quotedTweet, df_P3 #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P3_agrup_hist = df_P3_mentionedUsers.groupby(df_P3_mentionedUsers['username'])['id'].count()\n",
    "df_P3_retw_hist_agrup = df_P3_mentionedUsers_quot.groupby(df_P3_mentionedUsers_quot['username'])['id'].count()\n",
    "\n",
    "del df_P3_mentionedUsers, df_P3_mentionedUsers_quot #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P3_merged_menc = pd.merge(df_P3_agrup_hist, df_P3_retw_hist_agrup, on='username', how='outer', suffixes=('_dftweets', '_dfretweets'))\n",
    "df_P3_merged_menc['cantidad_total'] = df_P3_merged_menc['id_dftweets'].fillna(0) + df_P3_merged_menc['id_dfretweets'].fillna(0)\n",
    "\n",
    "df_P3_merged_menc = df_P3_merged_menc.sort_values(by='cantidad_total', ascending=False).head(10).reset_index()\n",
    "\n",
    "del df_P3_agrup_hist, df_P3_retw_hist_agrup #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuanJo\\AppData\\Local\\Temp\\ipykernel_17556\\1316740264.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  P3_short['cantidad_total'] = P3_short['cantidad_total'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P3_short=df_P3_merged_menc[['username','cantidad_total']]\n",
    "P3_short['cantidad_total'] = P3_short['cantidad_total'].astype(int)\n",
    "\n",
    "del df_P3_merged_menc #MEM\n",
    "gc.collect() #MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2623), ('Kisanektamorcha', 2045), ('RakeshTikaitBKU', 1848), ('PMOIndia', 1560), ('GretaThunberg', 1274), ('RahulGandhi', 1252), ('rihanna', 1142), ('DelhiPolice', 1134), ('RaviSinghKA', 1127), ('UNHumanRights', 1057)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list_P3 = [(username, int(cantidad)) for username, cantidad in zip(P3_short['username'], P3_short['cantidad_total'])]\n",
    "print(output_list_P3)\n",
    "\n",
    "del P3_short #MEM\n",
    "gc.collect() #MEM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
